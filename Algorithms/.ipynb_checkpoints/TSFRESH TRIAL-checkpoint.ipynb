{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Jupyter notebook from backtest.ipynb\n",
      "Importing Jupyter notebook from stats_helper.ipynb\n",
      "Importing Jupyter notebook from preprocessing.ipynb\n",
      "Importing Jupyter notebook from helper_methods.ipynb\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import nbimporter\n",
    "import numpy as np\n",
    "import backtest as bt\n",
    "import preprocessing as pp\n",
    "import helper_methods as hm\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-NN Classifier Implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class K_Nearest_Neighbours_Classifier:\n",
    "    \n",
    "    def __init__(self, k_neighbours):\n",
    "        self.k_neighbours = k_neighbours\n",
    "    \n",
    "    # This function was meant to train the data - but no explicit training in K-NN\n",
    "    def fit(self, X_train, Y_train):\n",
    "        self.X_train = X_train\n",
    "        self.Y_train = Y_train\n",
    "        return\n",
    "    \n",
    "    \n",
    "    # This function uses the training data and the feature values to the data sample to be predicted on. \n",
    "    # Using the specified number of nearest neighbours, it returns the predicted classification of the specificed data sample\n",
    "    def predict_one(self, x_test_point):\n",
    "        distances = []\n",
    "        for i in range(len(self.X_train)):\n",
    "            # sum of square of distance of each feature - minkowski Distance with p = 2\n",
    "            distance = ((self.X_train[i, :] - x_test_point)**2).sum()\n",
    "            # appending the list of the distance for the point and its index to the list\n",
    "            distances.append([distance, i])\n",
    "\n",
    "        # Sorting using the distance from the sample point\n",
    "        distances = sorted(distances)\n",
    "\n",
    "        targets = []\n",
    "        # Finding the classification of the elements using the first 'k' elemets in the distances list i.e 'k' nearest neighbours\n",
    "        for i in range(self.k_neighbours):\n",
    "            # list of the indices of the 'k' nearest neighbours\n",
    "            index_of_training_data = distances[i][1]\n",
    "\n",
    "            # adding the nearest neighbours to the targets list\n",
    "            targets.append(self.Y_train[index_of_training_data])\n",
    "\n",
    "        # returns the most common entry among the targets\n",
    "        return Counter(targets).most_common(1)[0][0]\n",
    "    \n",
    "    \n",
    "    # This function uses the training data, the data samples to be predicted upon and the value of k\n",
    "    # It return the predicted classification values of the data samples given to it for prediction\n",
    "    def predict(self, x_test_data):\n",
    "        predictions = []\n",
    "\n",
    "        # making prediction for the testing data samples\n",
    "        for x_test in x_test_data:\n",
    "            predictions.append(self.predict_one(x_test))\n",
    "        return predictions\n",
    "    \n",
    "    \n",
    "    # This function uses the training data, the data samples to be predicted upon and the value of k\n",
    "    # It returns the predicted classification of the data samples given to it for prediction \n",
    "    # while updating the training data after each prediction\n",
    "    def predict_and_update(self, x_test_data, y_test_data):\n",
    "        predictions = []\n",
    "\n",
    "        # making prediction for the testing data samples\n",
    "        for i in range(len(x_test_data)):\n",
    "            x_test = x_test_data[i]\n",
    "            y_test = y_test_data[i]\n",
    "\n",
    "            y_pred = self.predict_one(x_test)\n",
    "            predictions.append(y_pred)\n",
    "\n",
    "            # updating the training dataset to include the point just predicted upon\n",
    "            self.X_train = np.append(self.X_train, [x_test], axis=0)\n",
    "            self.Y_train = np.append(self.Y_train, [y_test], axis=0)\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using CV to find Optimal parameters\n",
    "\n",
    "Sorting list: https://stackoverflow.com/questions/17555218/python-how-to-sort-a-list-of-lists-by-the-fourth-element-in-each-list  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_parameters_accuracy(accuracies):\n",
    "    print('#Features \\t #Neighbours \\t Accuracy')\n",
    "    for i in range(len(accuracies)):\n",
    "        print(accuracies[i][0], '\\t\\t', accuracies[i][1], '\\t\\t', accuracies[i][2])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_values(max_features, max_neighbours, num_splits = 10, symbol_name = 'AAPL', use_implementation = True):\n",
    "    accuracies = list()\n",
    "    for num_features in range(1, max_features + 1, 1):\n",
    "        print('Features:', num_features)\n",
    "        \n",
    "        X_train, X_test, Y_train, Y_test = hm.prepare_data(num_features, symbol_name, is_binary_ouput=True)\n",
    "        X_train, X_test, Y_train, Y_test = X_train.values, X_test.values, Y_train.values, Y_test.values\n",
    "        \n",
    "        for k_neighbours in range(1, max_neighbours + 1, 2):\n",
    "            print('Neighbours ------------------------>', k_neighbours)\n",
    "#             knn_tscv = K_Nearest_Neighbours_Classifier(k_neighbours=k_neighbours)\n",
    "            knn_tscv = KNeighborsClassifier(n_neighbors=k_neighbours)\n",
    "#             knn_tscv = KNeighborsClassifier(n_neighbors=int(len(X_train) ** 0.5))\n",
    "            if use_implementation:\n",
    "                neighbour_accuracy = hm.timeSeriesCV(X_train, Y_train, num_splits, knn_tscv, is_classification=True)\n",
    "            else:\n",
    "                neighbour_accuracy = hm.rolling_cross_validation(X_train, Y_train, num_splits, knn_tscv, is_classification=True)\n",
    "            accuracies.append([num_features, k_neighbours, neighbour_accuracy])\n",
    "    \n",
    "    print_parameters_accuracy(accuracies)\n",
    "    \n",
    "    # Sorting the accuracies\n",
    "    accuracies.sort(reverse=True, key=lambda x: x[2])\n",
    "    print_parameters_accuracy(accuracies)\n",
    "    \n",
    "    return accuracies[0][0], accuracies[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_ready(symbol_name, max_features=5, max_neighbours=11):\n",
    "    start_time = time.time()\n",
    "    num_features, k_neighbours = find_optimal_values(max_features=max_features, max_neighbours=max_neighbours, num_splits=10, symbol_name = symbol_name)\n",
    "    end_time = time.time()\n",
    "    print('Time taken for Cross Validation:', end_time - start_time)\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = hm.prepare_data(num_features, symbol_name)\n",
    "    X_train, X_test, Y_train, Y_test = X_train.values, X_test.values, Y_train.values, Y_test.values\n",
    "    return X_train, X_test, Y_train, Y_test, k_neighbours    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. SKLearn KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sklearn_KNN_forecast(X_train, X_test, Y_train, Y_test, k_neighbours):\n",
    "    print('SKLEARN INBUILT')\n",
    "    clf = KNeighborsClassifier(n_neighbors=k_neighbours)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    print('Accuracy Score --', clf.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Predicting using Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def implemented_KNN_forecast(X_train, X_test, Y_train, Y_test, k_neighbours):\n",
    "    knn = K_Nearest_Neighbours_Classifier(k_neighbours)\n",
    "    knn.fit(X_train, Y_train)\n",
    "    \n",
    "    print('IMPLEMENTATION') \n",
    "    Y_pred = knn.predict(X_test)\n",
    "    hm.accuracy_metrics(Y_test, Y_pred)\n",
    "\n",
    "    print('IMPLEMENTATION WITH TRAINING UPDATES') \n",
    "    Y_pred = knn.predict_and_update(X_test, Y_test)\n",
    "    hm.accuracy_metrics(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Sliding Window/Sliding Simulation Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(X_train, X_test, Y_train, Y_test, k_neighbours, window_size):\n",
    "    knn = K_Nearest_Neighbours_Classifier(k_neighbours)\n",
    "    \n",
    "    print(X_train[:window_size, :])\n",
    "    print(Y_train[:window_size])\n",
    "    print(len(Y_test))\n",
    "    \n",
    "    X_train = X_train[:window_size, :]\n",
    "    Y_train = Y_train[:window_size]\n",
    "    knn.fit(X_train, Y_train)\n",
    "    Y_pred = knn.predict(X_test[-1:, 0])\n",
    "    \n",
    "    \n",
    "    for i in range(len(Y_test)):\n",
    "        knn.fit\n",
    "    \n",
    "    x_train = X_train[:window_size, :]\n",
    "    knn.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast(X_train, X_test, Y_train, Y_test, k_neighbours):\n",
    "    print('Number of Neighbours --', k_neighbours)\n",
    "    sklearn_KNN_forecast(X_train, X_test, Y_train, Y_test, k_neighbours)\n",
    "    implemented_KNN_forecast(X_train, X_test, Y_train, Y_test, k_neighbours)\n",
    "#     sliding_window(X_train, X_test, Y_train, Y_test, k_neighbours, 5)\n",
    "\n",
    "# X_train, X_test, Y_train, Y_test = hm.prepare_data(2)\n",
    "# X_train, X_test, Y_train, Y_test = X_train.values, X_test.values, Y_train.values, Y_test.values\n",
    "# forecast(X_train, X_test, Y_train, Y_test, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_KNN(symbol_name):\n",
    "    max_features = 13\n",
    "    max_neighbours = 21\n",
    "    X_train, X_test, Y_train, Y_test, k_neighbours = get_data_ready(symbol_name, max_features, max_neighbours)\n",
    "    print(X_train)\n",
    "    forecast(X_train, X_test, Y_train, Y_test, k_neighbours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 1\n",
      "Neighbours ------------------------> 1\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5040871934604906 \n",
      "\n",
      "Neighbours ------------------------> 3\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.48894943990311834 \n",
      "\n",
      "Neighbours ------------------------> 5\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5034816833181955 \n",
      "\n",
      "Neighbours ------------------------> 7\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5028761731759007 \n",
      "\n",
      "Neighbours ------------------------> 9\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.50650923402967 \n",
      "\n",
      "Neighbours ------------------------> 11\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5083257644565546 \n",
      "\n",
      "Neighbours ------------------------> 13\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.49984862246442624 \n",
      "\n",
      "Neighbours ------------------------> 15\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5074174992431123 \n",
      "\n",
      "Features: 2\n",
      "Neighbours ------------------------> 1\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.49258250075688764 \n",
      "\n",
      "Neighbours ------------------------> 3\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.4977293369663942 \n",
      "\n",
      "Neighbours ------------------------> 5\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.48925219497426586 \n",
      "\n",
      "Neighbours ------------------------> 7\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5022706630336058 \n",
      "\n",
      "Neighbours ------------------------> 9\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.4977293369663942 \n",
      "\n",
      "Neighbours ------------------------> 11\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.49651831668180435 \n",
      "\n",
      "Neighbours ------------------------> 13\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.498940357250984 \n",
      "\n",
      "Neighbours ------------------------> 15\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.49258250075688775 \n",
      "\n",
      "Features: 3\n",
      "Neighbours ------------------------> 1\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5037844383893431 \n",
      "\n",
      "Neighbours ------------------------> 3\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5180139267332727 \n",
      "\n",
      "Neighbours ------------------------> 5\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5131698455949139 \n",
      "\n",
      "Neighbours ------------------------> 7\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5049954586739328 \n",
      "\n",
      "Neighbours ------------------------> 9\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.516802906448683 \n",
      "\n",
      "Neighbours ------------------------> 11\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5101422948834393 \n",
      "\n",
      "Neighbours ------------------------> 13\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5113533151680291 \n",
      "\n",
      "Neighbours ------------------------> 15\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5052982137450802 \n",
      "\n",
      "Features: 4\n",
      "Neighbours ------------------------> 1\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.509234029669997 \n",
      "\n",
      "Neighbours ------------------------> 3\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5192249470178626 \n",
      "\n",
      "Neighbours ------------------------> 5\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5149863760217984 \n",
      "\n",
      "Neighbours ------------------------> 7\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.50650923402967 \n",
      "\n",
      "Neighbours ------------------------> 9\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5134726006660612 \n",
      "\n",
      "Neighbours ------------------------> 11\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5059037238873751 \n",
      "\n",
      "Neighbours ------------------------> 13\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5046927036027853 \n",
      "\n",
      "Neighbours ------------------------> 15\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5131698455949137 \n",
      "\n",
      "Features: 5\n",
      "Neighbours ------------------------> 1\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5116560702391765 \n",
      "\n",
      "Neighbours ------------------------> 3\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5101422948834393 \n",
      "\n",
      "Neighbours ------------------------> 5\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5004541326067211 \n",
      "\n",
      "Neighbours ------------------------> 7\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.4947017862549197 \n",
      "\n",
      "Neighbours ------------------------> 9\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5028761731759007 \n",
      "\n",
      "Neighbours ------------------------> 11\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5119588253103239 \n",
      "\n",
      "Neighbours ------------------------> 13\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5140781108083561 \n",
      "\n",
      "Neighbours ------------------------> 15\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5146836209506509 \n",
      "\n",
      "Features: 6\n",
      "Neighbours ------------------------> 1\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5016651528913109 \n",
      "\n",
      "Neighbours ------------------------> 3\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5004541326067211 \n",
      "\n",
      "Neighbours ------------------------> 5\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5077202543142597 \n",
      "\n",
      "Neighbours ------------------------> 7\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5034816833181955 \n",
      "\n",
      "Neighbours ------------------------> 9\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5034816833181955 \n",
      "\n",
      "Neighbours ------------------------> 11\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5019679079624583 \n",
      "\n",
      "Neighbours ------------------------> 13\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5007568876778686 \n",
      "\n",
      "Neighbours ------------------------> 15\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5110505600968817 \n",
      "\n",
      "Features: 7\n",
      "Neighbours ------------------------> 1\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5098395398122918 \n",
      "\n",
      "Neighbours ------------------------> 3\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.511958825310324 \n",
      "\n",
      "Neighbours ------------------------> 5\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5113533151680291 \n",
      "\n",
      "Neighbours ------------------------> 7\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5116560702391765 \n",
      "\n",
      "Neighbours ------------------------> 9\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5065092340296701 \n",
      "\n",
      "Neighbours ------------------------> 11\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5140781108083561 \n",
      "\n",
      "Neighbours ------------------------> 13\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5152891310929458 \n",
      "\n",
      "Neighbours ------------------------> 15\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5107478050257341 \n",
      "\n",
      "Features: 8\n",
      "Neighbours ------------------------> 1\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.516802906448683 \n",
      "\n",
      "Neighbours ------------------------> 3\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5062064789585226 \n",
      "\n",
      "Neighbours ------------------------> 5\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5137753557372087 \n",
      "\n",
      "Neighbours ------------------------> 7\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5128670905237663 \n",
      "\n",
      "Neighbours ------------------------> 9\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5116560702391765 \n",
      "\n",
      "Neighbours ------------------------> 11\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5143808658795035 \n",
      "\n",
      "Neighbours ------------------------> 13\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5122615803814714 \n",
      "\n",
      "Neighbours ------------------------> 15\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5201332122313049 \n",
      "\n",
      "Features: 9\n",
      "Neighbours ------------------------> 1\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5127504553734061 \n",
      "\n",
      "Neighbours ------------------------> 3\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5027322404371586 \n",
      "\n",
      "Neighbours ------------------------> 5\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5048573163327261 \n",
      "\n",
      "Neighbours ------------------------> 7\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5085003035822708 \n",
      "\n",
      "Neighbours ------------------------> 9\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5118397085610201 \n",
      "\n",
      "Neighbours ------------------------> 11\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5230722525804493 \n",
      "\n",
      "Neighbours ------------------------> 13\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5188221007893139 \n",
      "\n",
      "Neighbours ------------------------> 15\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5203400121432907 \n",
      "\n",
      "Features: 10\n",
      "Neighbours ------------------------> 1\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.4993928354584093 \n",
      "\n",
      "Neighbours ------------------------> 3\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5003035822707953 \n",
      "\n",
      "Neighbours ------------------------> 5\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5018214936247722 \n",
      "\n",
      "Neighbours ------------------------> 7\n",
      "Implemented Rolling Cross Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5109289617486339 \n",
      "\n",
      "Neighbours ------------------------> 9\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5154826958105647 \n",
      "\n",
      "Neighbours ------------------------> 11\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5145719489981785 \n",
      "\n",
      "Neighbours ------------------------> 13\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5121432908318153 \n",
      "\n",
      "Neighbours ------------------------> 15\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5200364298724955 \n",
      "\n",
      "Features: 11\n",
      "Neighbours ------------------------> 1\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.49726775956284147 \n",
      "\n",
      "Neighbours ------------------------> 3\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.4893746205221615 \n",
      "\n",
      "Neighbours ------------------------> 5\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.509411050394657 \n",
      "\n",
      "Neighbours ------------------------> 7\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5063752276867031 \n",
      "\n",
      "Neighbours ------------------------> 9\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5097146326654524 \n",
      "\n",
      "Neighbours ------------------------> 11\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5121432908318154 \n",
      "\n",
      "Neighbours ------------------------> 13\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.51183970856102 \n",
      "\n",
      "Neighbours ------------------------> 15\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5115361262902246 \n",
      "\n",
      "Features: 12\n",
      "Neighbours ------------------------> 1\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.50394656952034 \n",
      "\n",
      "Neighbours ------------------------> 3\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.49787492410443235 \n",
      "\n",
      "Neighbours ------------------------> 5\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.4969641772920462 \n",
      "\n",
      "Neighbours ------------------------> 7\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.4924104432301154 \n",
      "\n",
      "Neighbours ------------------------> 9\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.4987856709168185 \n",
      "\n",
      "Neighbours ------------------------> 11\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.51183970856102 \n",
      "\n",
      "Neighbours ------------------------> 13\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5018214936247722 \n",
      "\n",
      "Neighbours ------------------------> 15\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5054644808743168 \n",
      "\n",
      "Features: 13\n",
      "Neighbours ------------------------> 1\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.4972677595628416 \n",
      "\n",
      "Neighbours ------------------------> 3\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5009107468123862 \n",
      "\n",
      "Neighbours ------------------------> 5\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5006071645415908 \n",
      "\n",
      "Neighbours ------------------------> 7\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.4963570127504553 \n",
      "\n",
      "Neighbours ------------------------> 9\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.4993928354584093 \n",
      "\n",
      "Neighbours ------------------------> 11\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5024286581663631 \n",
      "\n",
      "Neighbours ------------------------> 13\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5069823922282939 \n",
      "\n",
      "Neighbours ------------------------> 15\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5069823922282939 \n",
      "\n",
      "Features: 14\n",
      "Neighbours ------------------------> 1\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5045537340619307 \n",
      "\n",
      "Neighbours ------------------------> 3\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5027322404371585 \n",
      "\n",
      "Neighbours ------------------------> 5\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5091074681238615 \n",
      "\n",
      "Neighbours ------------------------> 7\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5151791135397692 \n",
      "\n",
      "Neighbours ------------------------> 9\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5148755312689739 \n",
      "\n",
      "Neighbours ------------------------> 11\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5103217972070432 \n",
      "\n",
      "Neighbours ------------------------> 13\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5185185185185186 \n",
      "\n",
      "Neighbours ------------------------> 15\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.517304189435337 \n",
      "\n",
      "Features: 15\n",
      "Neighbours ------------------------> 1\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.49605343047966 \n",
      "\n",
      "Neighbours ------------------------> 3\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5009107468123862 \n",
      "\n",
      "Neighbours ------------------------> 5\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5075895567698846 \n",
      "\n",
      "Neighbours ------------------------> 7\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5045537340619308 \n",
      "\n",
      "Neighbours ------------------------> 9\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5091074681238615 \n",
      "\n",
      "Neighbours ------------------------> 11\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5121432908318154 \n",
      "\n",
      "Neighbours ------------------------> 13\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5063752276867032 \n",
      "\n",
      "Neighbours ------------------------> 15\n",
      "Implemented Rolling Cross Validation\n",
      "Accuracy: 0.5030358227079539 \n",
      "\n",
      "#Features \t #Neighbours \t Accuracy\n",
      "1 \t\t 1 \t\t 0.5040871934604906\n",
      "1 \t\t 3 \t\t 0.48894943990311834\n",
      "1 \t\t 5 \t\t 0.5034816833181955\n",
      "1 \t\t 7 \t\t 0.5028761731759007\n",
      "1 \t\t 9 \t\t 0.50650923402967\n",
      "1 \t\t 11 \t\t 0.5083257644565546\n",
      "1 \t\t 13 \t\t 0.49984862246442624\n",
      "1 \t\t 15 \t\t 0.5074174992431123\n",
      "2 \t\t 1 \t\t 0.49258250075688764\n",
      "2 \t\t 3 \t\t 0.4977293369663942\n",
      "2 \t\t 5 \t\t 0.48925219497426586\n",
      "2 \t\t 7 \t\t 0.5022706630336058\n",
      "2 \t\t 9 \t\t 0.4977293369663942\n",
      "2 \t\t 11 \t\t 0.49651831668180435\n",
      "2 \t\t 13 \t\t 0.498940357250984\n",
      "2 \t\t 15 \t\t 0.49258250075688775\n",
      "3 \t\t 1 \t\t 0.5037844383893431\n",
      "3 \t\t 3 \t\t 0.5180139267332727\n",
      "3 \t\t 5 \t\t 0.5131698455949139\n",
      "3 \t\t 7 \t\t 0.5049954586739328\n",
      "3 \t\t 9 \t\t 0.516802906448683\n",
      "3 \t\t 11 \t\t 0.5101422948834393\n",
      "3 \t\t 13 \t\t 0.5113533151680291\n",
      "3 \t\t 15 \t\t 0.5052982137450802\n",
      "4 \t\t 1 \t\t 0.509234029669997\n",
      "4 \t\t 3 \t\t 0.5192249470178626\n",
      "4 \t\t 5 \t\t 0.5149863760217984\n",
      "4 \t\t 7 \t\t 0.50650923402967\n",
      "4 \t\t 9 \t\t 0.5134726006660612\n",
      "4 \t\t 11 \t\t 0.5059037238873751\n",
      "4 \t\t 13 \t\t 0.5046927036027853\n",
      "4 \t\t 15 \t\t 0.5131698455949137\n",
      "5 \t\t 1 \t\t 0.5116560702391765\n",
      "5 \t\t 3 \t\t 0.5101422948834393\n",
      "5 \t\t 5 \t\t 0.5004541326067211\n",
      "5 \t\t 7 \t\t 0.4947017862549197\n",
      "5 \t\t 9 \t\t 0.5028761731759007\n",
      "5 \t\t 11 \t\t 0.5119588253103239\n",
      "5 \t\t 13 \t\t 0.5140781108083561\n",
      "5 \t\t 15 \t\t 0.5146836209506509\n",
      "6 \t\t 1 \t\t 0.5016651528913109\n",
      "6 \t\t 3 \t\t 0.5004541326067211\n",
      "6 \t\t 5 \t\t 0.5077202543142597\n",
      "6 \t\t 7 \t\t 0.5034816833181955\n",
      "6 \t\t 9 \t\t 0.5034816833181955\n",
      "6 \t\t 11 \t\t 0.5019679079624583\n",
      "6 \t\t 13 \t\t 0.5007568876778686\n",
      "6 \t\t 15 \t\t 0.5110505600968817\n",
      "7 \t\t 1 \t\t 0.5098395398122918\n",
      "7 \t\t 3 \t\t 0.511958825310324\n",
      "7 \t\t 5 \t\t 0.5113533151680291\n",
      "7 \t\t 7 \t\t 0.5116560702391765\n",
      "7 \t\t 9 \t\t 0.5065092340296701\n",
      "7 \t\t 11 \t\t 0.5140781108083561\n",
      "7 \t\t 13 \t\t 0.5152891310929458\n",
      "7 \t\t 15 \t\t 0.5107478050257341\n",
      "8 \t\t 1 \t\t 0.516802906448683\n",
      "8 \t\t 3 \t\t 0.5062064789585226\n",
      "8 \t\t 5 \t\t 0.5137753557372087\n",
      "8 \t\t 7 \t\t 0.5128670905237663\n",
      "8 \t\t 9 \t\t 0.5116560702391765\n",
      "8 \t\t 11 \t\t 0.5143808658795035\n",
      "8 \t\t 13 \t\t 0.5122615803814714\n",
      "8 \t\t 15 \t\t 0.5201332122313049\n",
      "9 \t\t 1 \t\t 0.5127504553734061\n",
      "9 \t\t 3 \t\t 0.5027322404371586\n",
      "9 \t\t 5 \t\t 0.5048573163327261\n",
      "9 \t\t 7 \t\t 0.5085003035822708\n",
      "9 \t\t 9 \t\t 0.5118397085610201\n",
      "9 \t\t 11 \t\t 0.5230722525804493\n",
      "9 \t\t 13 \t\t 0.5188221007893139\n",
      "9 \t\t 15 \t\t 0.5203400121432907\n",
      "10 \t\t 1 \t\t 0.4993928354584093\n",
      "10 \t\t 3 \t\t 0.5003035822707953\n",
      "10 \t\t 5 \t\t 0.5018214936247722\n",
      "10 \t\t 7 \t\t 0.5109289617486339\n",
      "10 \t\t 9 \t\t 0.5154826958105647\n",
      "10 \t\t 11 \t\t 0.5145719489981785\n",
      "10 \t\t 13 \t\t 0.5121432908318153\n",
      "10 \t\t 15 \t\t 0.5200364298724955\n",
      "11 \t\t 1 \t\t 0.49726775956284147\n",
      "11 \t\t 3 \t\t 0.4893746205221615\n",
      "11 \t\t 5 \t\t 0.509411050394657\n",
      "11 \t\t 7 \t\t 0.5063752276867031\n",
      "11 \t\t 9 \t\t 0.5097146326654524\n",
      "11 \t\t 11 \t\t 0.5121432908318154\n",
      "11 \t\t 13 \t\t 0.51183970856102\n",
      "11 \t\t 15 \t\t 0.5115361262902246\n",
      "12 \t\t 1 \t\t 0.50394656952034\n",
      "12 \t\t 3 \t\t 0.49787492410443235\n",
      "12 \t\t 5 \t\t 0.4969641772920462\n",
      "12 \t\t 7 \t\t 0.4924104432301154\n",
      "12 \t\t 9 \t\t 0.4987856709168185\n",
      "12 \t\t 11 \t\t 0.51183970856102\n",
      "12 \t\t 13 \t\t 0.5018214936247722\n",
      "12 \t\t 15 \t\t 0.5054644808743168\n",
      "13 \t\t 1 \t\t 0.4972677595628416\n",
      "13 \t\t 3 \t\t 0.5009107468123862\n",
      "13 \t\t 5 \t\t 0.5006071645415908\n",
      "13 \t\t 7 \t\t 0.4963570127504553\n",
      "13 \t\t 9 \t\t 0.4993928354584093\n",
      "13 \t\t 11 \t\t 0.5024286581663631\n",
      "13 \t\t 13 \t\t 0.5069823922282939\n",
      "13 \t\t 15 \t\t 0.5069823922282939\n",
      "14 \t\t 1 \t\t 0.5045537340619307\n",
      "14 \t\t 3 \t\t 0.5027322404371585\n",
      "14 \t\t 5 \t\t 0.5091074681238615\n",
      "14 \t\t 7 \t\t 0.5151791135397692\n",
      "14 \t\t 9 \t\t 0.5148755312689739\n",
      "14 \t\t 11 \t\t 0.5103217972070432\n",
      "14 \t\t 13 \t\t 0.5185185185185186\n",
      "14 \t\t 15 \t\t 0.517304189435337\n",
      "15 \t\t 1 \t\t 0.49605343047966\n",
      "15 \t\t 3 \t\t 0.5009107468123862\n",
      "15 \t\t 5 \t\t 0.5075895567698846\n",
      "15 \t\t 7 \t\t 0.5045537340619308\n",
      "15 \t\t 9 \t\t 0.5091074681238615\n",
      "15 \t\t 11 \t\t 0.5121432908318154\n",
      "15 \t\t 13 \t\t 0.5063752276867032\n",
      "15 \t\t 15 \t\t 0.5030358227079539\n",
      "\n",
      "#Features \t #Neighbours \t Accuracy\n",
      "9 \t\t 11 \t\t 0.5230722525804493\n",
      "9 \t\t 15 \t\t 0.5203400121432907\n",
      "8 \t\t 15 \t\t 0.5201332122313049\n",
      "10 \t\t 15 \t\t 0.5200364298724955\n",
      "4 \t\t 3 \t\t 0.5192249470178626\n",
      "9 \t\t 13 \t\t 0.5188221007893139\n",
      "14 \t\t 13 \t\t 0.5185185185185186\n",
      "3 \t\t 3 \t\t 0.5180139267332727\n",
      "14 \t\t 15 \t\t 0.517304189435337\n",
      "3 \t\t 9 \t\t 0.516802906448683\n",
      "8 \t\t 1 \t\t 0.516802906448683\n",
      "10 \t\t 9 \t\t 0.5154826958105647\n",
      "7 \t\t 13 \t\t 0.5152891310929458\n",
      "14 \t\t 7 \t\t 0.5151791135397692\n",
      "4 \t\t 5 \t\t 0.5149863760217984\n",
      "14 \t\t 9 \t\t 0.5148755312689739\n",
      "5 \t\t 15 \t\t 0.5146836209506509\n",
      "10 \t\t 11 \t\t 0.5145719489981785\n",
      "8 \t\t 11 \t\t 0.5143808658795035\n",
      "5 \t\t 13 \t\t 0.5140781108083561\n",
      "7 \t\t 11 \t\t 0.5140781108083561\n",
      "8 \t\t 5 \t\t 0.5137753557372087\n",
      "4 \t\t 9 \t\t 0.5134726006660612\n",
      "3 \t\t 5 \t\t 0.5131698455949139\n",
      "4 \t\t 15 \t\t 0.5131698455949137\n",
      "8 \t\t 7 \t\t 0.5128670905237663\n",
      "9 \t\t 1 \t\t 0.5127504553734061\n",
      "8 \t\t 13 \t\t 0.5122615803814714\n",
      "11 \t\t 11 \t\t 0.5121432908318154\n",
      "15 \t\t 11 \t\t 0.5121432908318154\n",
      "10 \t\t 13 \t\t 0.5121432908318153\n",
      "7 \t\t 3 \t\t 0.511958825310324\n",
      "5 \t\t 11 \t\t 0.5119588253103239\n",
      "9 \t\t 9 \t\t 0.5118397085610201\n",
      "11 \t\t 13 \t\t 0.51183970856102\n",
      "12 \t\t 11 \t\t 0.51183970856102\n",
      "5 \t\t 1 \t\t 0.5116560702391765\n",
      "7 \t\t 7 \t\t 0.5116560702391765\n",
      "8 \t\t 9 \t\t 0.5116560702391765\n",
      "11 \t\t 15 \t\t 0.5115361262902246\n",
      "3 \t\t 13 \t\t 0.5113533151680291\n",
      "7 \t\t 5 \t\t 0.5113533151680291\n",
      "6 \t\t 15 \t\t 0.5110505600968817\n",
      "10 \t\t 7 \t\t 0.5109289617486339\n",
      "7 \t\t 15 \t\t 0.5107478050257341\n",
      "14 \t\t 11 \t\t 0.5103217972070432\n",
      "3 \t\t 11 \t\t 0.5101422948834393\n",
      "5 \t\t 3 \t\t 0.5101422948834393\n",
      "7 \t\t 1 \t\t 0.5098395398122918\n",
      "11 \t\t 9 \t\t 0.5097146326654524\n",
      "11 \t\t 5 \t\t 0.509411050394657\n",
      "4 \t\t 1 \t\t 0.509234029669997\n",
      "14 \t\t 5 \t\t 0.5091074681238615\n",
      "15 \t\t 9 \t\t 0.5091074681238615\n",
      "9 \t\t 7 \t\t 0.5085003035822708\n",
      "1 \t\t 11 \t\t 0.5083257644565546\n",
      "6 \t\t 5 \t\t 0.5077202543142597\n",
      "15 \t\t 5 \t\t 0.5075895567698846\n",
      "1 \t\t 15 \t\t 0.5074174992431123\n",
      "13 \t\t 13 \t\t 0.5069823922282939\n",
      "13 \t\t 15 \t\t 0.5069823922282939\n",
      "7 \t\t 9 \t\t 0.5065092340296701\n",
      "1 \t\t 9 \t\t 0.50650923402967\n",
      "4 \t\t 7 \t\t 0.50650923402967\n",
      "15 \t\t 13 \t\t 0.5063752276867032\n",
      "11 \t\t 7 \t\t 0.5063752276867031\n",
      "8 \t\t 3 \t\t 0.5062064789585226\n",
      "4 \t\t 11 \t\t 0.5059037238873751\n",
      "12 \t\t 15 \t\t 0.5054644808743168\n",
      "3 \t\t 15 \t\t 0.5052982137450802\n",
      "3 \t\t 7 \t\t 0.5049954586739328\n",
      "9 \t\t 5 \t\t 0.5048573163327261\n",
      "4 \t\t 13 \t\t 0.5046927036027853\n",
      "15 \t\t 7 \t\t 0.5045537340619308\n",
      "14 \t\t 1 \t\t 0.5045537340619307\n",
      "1 \t\t 1 \t\t 0.5040871934604906\n",
      "12 \t\t 1 \t\t 0.50394656952034\n",
      "3 \t\t 1 \t\t 0.5037844383893431\n",
      "1 \t\t 5 \t\t 0.5034816833181955\n",
      "6 \t\t 7 \t\t 0.5034816833181955\n",
      "6 \t\t 9 \t\t 0.5034816833181955\n",
      "15 \t\t 15 \t\t 0.5030358227079539\n",
      "1 \t\t 7 \t\t 0.5028761731759007\n",
      "5 \t\t 9 \t\t 0.5028761731759007\n",
      "9 \t\t 3 \t\t 0.5027322404371586\n",
      "14 \t\t 3 \t\t 0.5027322404371585\n",
      "13 \t\t 11 \t\t 0.5024286581663631\n",
      "2 \t\t 7 \t\t 0.5022706630336058\n",
      "6 \t\t 11 \t\t 0.5019679079624583\n",
      "10 \t\t 5 \t\t 0.5018214936247722\n",
      "12 \t\t 13 \t\t 0.5018214936247722\n",
      "6 \t\t 1 \t\t 0.5016651528913109\n",
      "13 \t\t 3 \t\t 0.5009107468123862\n",
      "15 \t\t 3 \t\t 0.5009107468123862\n",
      "6 \t\t 13 \t\t 0.5007568876778686\n",
      "13 \t\t 5 \t\t 0.5006071645415908\n",
      "5 \t\t 5 \t\t 0.5004541326067211\n",
      "6 \t\t 3 \t\t 0.5004541326067211\n",
      "10 \t\t 3 \t\t 0.5003035822707953\n",
      "1 \t\t 13 \t\t 0.49984862246442624\n",
      "10 \t\t 1 \t\t 0.4993928354584093\n",
      "13 \t\t 9 \t\t 0.4993928354584093\n",
      "2 \t\t 13 \t\t 0.498940357250984\n",
      "12 \t\t 9 \t\t 0.4987856709168185\n",
      "12 \t\t 3 \t\t 0.49787492410443235\n",
      "2 \t\t 3 \t\t 0.4977293369663942\n",
      "2 \t\t 9 \t\t 0.4977293369663942\n",
      "13 \t\t 1 \t\t 0.4972677595628416\n",
      "11 \t\t 1 \t\t 0.49726775956284147\n",
      "12 \t\t 5 \t\t 0.4969641772920462\n",
      "2 \t\t 11 \t\t 0.49651831668180435\n",
      "13 \t\t 7 \t\t 0.4963570127504553\n",
      "15 \t\t 1 \t\t 0.49605343047966\n",
      "5 \t\t 7 \t\t 0.4947017862549197\n",
      "2 \t\t 15 \t\t 0.49258250075688775\n",
      "2 \t\t 1 \t\t 0.49258250075688764\n",
      "12 \t\t 7 \t\t 0.4924104432301154\n",
      "11 \t\t 3 \t\t 0.4893746205221615\n",
      "2 \t\t 5 \t\t 0.48925219497426586\n",
      "1 \t\t 3 \t\t 0.48894943990311834\n",
      "\n",
      "Time taken for Cross Validation: 48.299768924713135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00545387 -0.0011997   0.01421733 ... -0.00130402 -0.0017766\n",
      "  -0.01389892]\n",
      " [-0.0011997   0.01421733 -0.02415932 ... -0.0017766  -0.01389892\n",
      "  -0.02098916]\n",
      " [ 0.01421733 -0.02415932 -0.00017376 ... -0.01389892 -0.02098916\n",
      "  -0.00920093]\n",
      " ...\n",
      " [ 0.00156169  0.00055946 -0.00385552 ...  0.00283669  0.00502638\n",
      "   0.0002724 ]\n",
      " [ 0.00055946 -0.00385552 -0.00674357 ...  0.00502638  0.0002724\n",
      "  -0.00267245]\n",
      " [-0.00385552 -0.00674357  0.00518592 ...  0.0002724  -0.00267245\n",
      "  -0.00493849]]\n",
      "Number of Neighbours -- 11\n",
      "SKLEARN INBUILT\n",
      "Accuracy Score -- 0.4918300653594771\n",
      "IMPLEMENTATION\n",
      "------------------------------------------------\n",
      "Accuracy:  0.4918300653594771\n",
      "Matthews Correlation Coefficient:  -0.015576305463697822\n",
      "Cohen Kappa Score:  -0.015407268304133526\n",
      "Confustion Matrix\n",
      "[[342 266]\n",
      " [356 260]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.49      0.56      0.52       608\n",
      "         1.0       0.49      0.42      0.46       616\n",
      "\n",
      "   micro avg       0.49      0.49      0.49      1224\n",
      "   macro avg       0.49      0.49      0.49      1224\n",
      "weighted avg       0.49      0.49      0.49      1224\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "IMPLEMENTATION WITH TRAINING UPDATES\n",
      "------------------------------------------------\n",
      "Accuracy:  0.5008169934640523\n",
      "Matthews Correlation Coefficient:  0.002820207474804811\n",
      "Cohen Kappa Score:  0.002773540424351739\n",
      "Confustion Matrix\n",
      "[[358 250]\n",
      " [361 255]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.50      0.59      0.54       608\n",
      "         1.0       0.50      0.41      0.45       616\n",
      "\n",
      "   micro avg       0.50      0.50      0.50      1224\n",
      "   macro avg       0.50      0.50      0.50      1224\n",
      "weighted avg       0.50      0.50      0.50      1224\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiYAAAGfCAYAAABr4xlmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3XeYVeW1+PHvYoAA0hQRafaCHSMq9pKYWBKxx14Rr+VeNWpirDG2aDRGY0lQUCxRsXO59hK7IiqgiEZiRBhR6YioMDPv74858huUKcqZmb0P34/Pfjxn7/ecd28fh1mstd69I6WEJElSFrRo7hOQJEn6hoGJJEnKDAMTSZKUGQYmkiQpMwxMJElSZhiYSJKkzDAwkSRJmWFgIkmSMsPARJIkZUbLxp5gweSx3lpWagbt1ty9uU9BWmZVLCiPppxv4fQPiva7ttWKa9R67hHRBngO+BHVMcS9KaXzIyKAi4D9gUrghpTSNYX9VwO7A/OBI1NKb9Q1f6MHJpIkqWR8DeycUpoXEa2AFyLiEWA9oDfQJ6VUFRErFcbvBqxd2LYEbij8u1YGJpIk5V1VZZNMk6ofsDev8LZVYUvA8cDBKaWqwrjPCmMGALcWPvdKRHSOiO4ppam1zWGPiSRJarCIKIuIMcBnwBMppVeBNYFfRcToiHgkItYuDO8JTK7x8SmFfbUyMJEkKe9SVdG2iBhUCDC+2QYtNlVKlSmlvkAvYIuI2JDqnpOvUkr9gBuBoT/0UizlSJKUd1VVRfuqlNJgYHADxs2OiGeAXanOhNxfOPQAcHPhdTnVvSff6FXYVyszJpIkqUEiomtEdC68bgvsArwLPAjsVBi2A/CvwusRwOFRrT8wp67+EjBjIklS7hV6TptCd2BYRJRRndwYnlIaGREvAHdExKlUN8cOLIx/mOqlwhOpXi58VH0TGJhIkpR3RSzl1CWlNA7YdAn7ZwN7LGF/Ak78PnNYypEkSZlhxkSSpLxrulJOozMwkSQp75roBmtNwVKOJEnKDDMmkiTlnaUcSZKUGU20KqcpWMqRJEmZYcZEkqSca8IbrDU6AxNJkvLOUo4kSVLxmTGRJCnvLOVIkqTM8AZrkiRJxWfGRJKkvLOUI0mSMsNVOZIkScVnxkSSpLyzlCNJkjLDUo4kSVLxmTGRJCnnUiqd+5gYmEiSlHcl1GNiKUeSJGWGGRNJkvKuhJpfDUwkScq7EirlGJhIkpR3PsRPkiSp+MyYSJKUd5ZyJElSZpRQ86ulHEmSlBlmTCRJyjtLOZIkKTMs5UiSJBWfGRNJkvKuhDImBiaSJOVcKT1d2FKOJEnKDDMmkiTlnaUcSZKUGSW0XNhSjiRJygwzJpIk5Z2lHEmSlBmWciRJkorPjIkkSXlnKUeSJGWGpRxJkqTiM2MiSVLeWcqRJEmZUUKBiaUcSZKUGWZMJEnKuxJqfjUwkSQp7yzlSJIkFZ8ZE0mS8s5SjiRJygxLOZIkScVnxkSSpLyzlCNJkjLDUo4kSVLxmTGRJCnvSihjYmAiSVLepdTcZ1A0lnIkSVJmmDGRJCnvSqiUY8ZEkqS8q6oq3laHiGgTEaMiYmxEjI+IC751/JqImFfj/Y8i4u6ImBgRr0bEavVdioGJJElqqK+BnVNKmwB9gV0joj9ARPQDlv/W+GOAWSmltYCrgMvqm8DARJKkvEtVxdvqmqbaNxmRVoUtRUQZ8CfgN9/6yABgWOH1vcBPIiLqmsPARJKkvCtiKSciBkXE6BrboJpTRURZRIwBPgOeSCm9CpwEjEgpTf3WmfUEJgOklCqAOUCXui7F5ldJkrRISmkwMLiO45VA34joDDwQEdsD+wM7FmN+MyaSJOVdSsXbGjxlmg08A+wErAVMjIgPgXYRMbEwrBzoDRARLYFOwIy6vteMiSRJeddEy4UjoiuwMKU0OyLaArsAl6WUVq4xZl6h2RVgBHAE8DKwH/B0SnVHPwYmkiSpoboDwwrNri2A4SmlkXWMHwLcVsigzAQOrG8CAxNJkvKuiTImKaVxwKb1jGlf4/VXVPefNJiBiSRJeVfPMt88sflVkiRlhhkTSZJyLlWVztOFDUwkSco7H+InSZJUfGZMJEnKuxJqfjUwkSQp70qox8RSjiRJygwzJpIk5V0JNb8amEiSlHcGJpIkKTO+x1OBs84eE0mSlBlmTCRJyjtLOcqirxcs4MhTz2fBwgoqKyvZZfv+nHjEAd8Z9+g/X+KGW+8hIlhnjVW5/OyTl2reOXPncfpFV/Hxp9Po0a0rV5x7Kp06tGfkU88z9K6HSCmxXLu2nHvyQNZdc7WlmkvKol69enDL0KtZqduKpJS46aY7+Ou1QxYbs8P2W3H/fUP5z4eTAXjwwYe56OK/LNW8rVu35pabr+bHm27EzJmzOOiQ45k0aQo//cl2XHzxWbRu3YoFCxZy5pkX8cw/X1yquZRxJbRc2MCkhLRu1YohV5xPu7ZtWFhRwRGnnMe2m/dlk/XXWTRm0pSpDLnzQW69+kI6dWjPjFlzGvz9r40Zz4OP/5OLf3PiYvuH3PUgW266EQMP2oub7nyQIXc9yK+PPZReK6/EzX/+PZ06tOf5UW9ywVWD+ce1lxTteqWsqKio4IzfXMCbY96mffvlGPXqozz51HNMmPD+YuNeeGEUA/Y+4nt//6qr9mLoTVfxk10Wf3r80UcdxKxZc+iz/rYccMCeXHrJ2Rx8yPFMnzGTvfY+kqlTP2WDDdbl4ZF3sOrq/ZbqGqWmUm+PSUT0iYjfRsQ1he23EbFeU5ycvp+IoF3bNgBUVFRSUVFJRCw25r6Hn+LAAT+nU4f2AHRZvtOiYzffPYIDT/gd+xx7OtcNG97geZ956TUG/GwHAAb8bAeeefE1APpusO6ieTZeb20+nTbjh1+clGGffPIZb455G4B5877g3Xffp2ePlRv8+YMP3oeXXxzJ6Nce5/rrLqNFi4a1/+35y59x2233AHDfff/HzjttC8CYMeOZOvVTAMaPf4+2bdvQunXr73NJyptUVbytmdX5f39E/Ba4CwhgVGEL4M6IOLPxT0/fV2VlFfsddwY77DeQ/pttxMbrrb3Y8Q+nfMykKVM57ORzOeSks3lh1BgAXho9lknlU7nzuku49++X886/PmD0uHcaNOeMWXPo2mV5AFZcofMSszAPPPI0226x6VJenZR9q67ai76bbMiro978zrH+/Tfj9dFPMHLEbaxfyGT26bMWB+y/J9vtsBf9Nv8ZlZWVHHzwPg2aq0fPlZk85WMAKisrmTNnLl0KP4vf2GefPXjzzbdZsGDBUl6ZMq0qFW9rZvWVco4BNkgpLay5MyL+DIwH/rikD0XEIGAQwHWXnsPAQ/YrwqmqIcrKWnDv3//E3HlfcMr5V/D+fz5i7dVXWXS8srKKSeVTGXrl+Xw6bSZH/vp87r/xCl56fSwvvz6O/f/rNwDM//IrPir/hH4br8/BJ53FgoULmf/lV8z5fB77HXcGAKcOPIRtNu+72PwRAd/K0owa8zb3P/oMt171h0a+eql5LbdcO4bffSO/Pv18Pv983mLH3njzLdZYawu++GI+u+26M/fdM5T1NtiWnXfalh9vuhGvvPwwAG3btmHatOkA3HvPTay22iq0bt2KVXr3ZPRrjwPw17/exLBb689qrr/+Olx68VnstsfBRb5SqfHUF5hUAT2ASd/a371wbIlSSoOBwQALJo9t/vBrGdSx/XJs3ncDXnxtzGKBSbeuK7BRn7Vp1bIlvbqvxGq9uvPRlKmkBMcctBcH/GKX73zXN30htfWYdFm+E9NmzKJrl+WZNmMWXTp3XHTsvQ8mcf6Vf+eGS39H504dGulqpebXsmVL7rn7Ru688wEefPCR7xyvGag88ujT/PWaS+jSZXkigttuv4ezz/nu3/P2238gUHuPycfln9C7Vw/Ky6dSVlZGp04dmTFjFgA9e3bn3nuGcNTRJ/PBB9/+I1ylJpXQqpz6CpmnAE9FxCMRMbiwPQo8BSzdUg4V3czZc5k77wsAvvp6Aa+8Po7VV+m52Jidt96C0WPHAzBrzlw+nDKVXt27sU2/TXjw0WeY/+VXAHw6fWaDG2N33KofDz3+LAAPPf4sO229OQBTP53Oqb+/gkvPPInVevUoyjVKWXXj4CuZ8O5E/nL14CUe79at66LXm/frS4sWLZgxYxZPP/MC++z9C7p27QLA8st3ZpVv/dzW5n9HPs5hh1UHK/vuu8eilTedOnVkxEO3ctbZl/DSy6OX5rKUF8tKKSel9GhErANsAXzzk1IOvJZSqmzsk9P3M23mLM657Doqq6pIKfGzHbZih/6bce0td7PBOmuy09b92GbzTXjp9bEMOPpUWrRowWmDDqVzpw5s3W8TPvionEP++2wA2rVtwx9/99+LNcfW5pgD9+L0i67igUefpvtKXbny3FMB+Nvt9zJ77jwuuuYmAMrKyrj7+iVW/6Rc22brzTns0P0Y99Y7i8ot5577R3r3rv5jc/CNt7HvPntw3HGHU1FRyVdffsUhh54AwIQJ73Pe7y/nkYfvpEWLYOHCCv7nf87mo4/K65136M13MeyWa3j3nReYNWs2Bxe+88QTjmKtNVfjnLNP5Zyzq38ed9v9IKbZgK4ciNTIt7G1lCM1j3Zr7t7cpyAtsyoWlEf9o4rni4sOLdrv2uXOub1Jz/3bvI+JJEl5l4ESTLH4rBxJkpQZZkwkScq7ElqVY2AiSVLeWcqRJEkqPjMmkiTlXQaecVMsBiaSJOWdpRxJkqTiM2MiSVLOldKzcgxMJEnKO0s5kiRJxWfGRJKkvCuhjImBiSRJeVdCy4Ut5UiSpMwwYyJJUt5ZypEkSVmRSigwsZQjSZIyw4yJJEl5V0IZEwMTSZLyroTu/GopR5IkZYYZE0mS8s5SjiRJyowSCkws5UiSpMwwYyJJUs6lVDoZEwMTSZLyzlKOJElS8ZkxkSQp70ooY2JgIklSzvmsHEmSpEZgxkSSpLwroYyJgYkkSXlXOo/KsZQjSZKyw4yJJEk5V0rNrwYmkiTlXQkFJpZyJElSZpgxkSQp70qo+dXARJKknCulHhNLOZIkqUEiok1EjIqIsRExPiIuKOy/IyLei4i3I2JoRLQq7I+IuCYiJkbEuIj4cX1zGJhIkpR3VUXc6vY1sHNKaROgL7BrRPQH7gD6ABsBbYGBhfG7AWsXtkHADfVNYClHkqSca6pSTkopAfMKb1sVtpRSevibMRExCuhVeDsAuLXwuVcionNEdE8pTa1tDjMmkiSpwSKiLCLGAJ8BT6SUXq1xrBVwGPBoYVdPYHKNj08p7KuVgYkkSXlXxFJORAyKiNE1tkE1p0opVaaU+lKdFdkiIjascfh64LmU0vM/9FIs5UiSlHOpiMuFU0qDgcENGDc7Ip4BdgXejojzga7AcTWGlQO9a7zvVdhXKzMmkiTlXRM1v0ZE14joXHjdFtgFeDciBgI/Bw5KabEwaQRweGF1Tn9gTl39JWDGRJIkNVx3YFhElFGd3BieUhoZERXAJODliAC4P6X0B+BhYHdgIjAfOKq+CQxMJEnKuWKWcuqcJ6VxwKZL2L/EeKKwGufE7zOHgYkkSXlXQrekt8dEkiRlhhkTSZJyrqlKOU3BwESSpJwrpcDEUo4kScoMMyaSJOVcKWVMDEwkScq7FM19BkVjKUeSJGWGGRNJknLOUo4kScqMVGUpR5IkqejMmEiSlHOWciRJUmYkV+VIkiQVnxkTSZJyzlKOJEnKDFflSJIkNQIzJpIk5VxKzX0GxWNgIklSzlnKkSRJagRmTCRJyrlSypgYmEiSlHOl1GNiKUeSJGWGGRNJknLOUo4kScoMn5UjSZLUCMyYSJKUcz4rR5IkZUaVpRxJkqTiM2MiSVLOlVLzq4GJJEk5V0rLhS3lSJKkzDBjIklSzpXSLekNTCRJyjlLOZIkSY3AjIkkSTlXSvcxMTCRJCnnSmm5sKUcSZKUGWZMJEnKOVflSJKkzCilHhNLOZIkKTPMmEiSlHOl1PxqYCJJUs6VUo+JpRxJkpQZjZ4xibYdGnsKSUvQ8UftmvsUJDWRUmp+tZQjSVLOlVKPiaUcSZKUGWZMJEnKOUs5kiQpM0poUY6BiSRJeVdKGRN7TCRJUmaYMZEkKedKaVWOgYkkSTlX1dwnUESWciRJUmaYMZEkKecSlnIkSVJGVJXQemFLOZIkKTPMmEiSlHNVlnIkSVJWlFKPiaUcSZKUGQYmkiTlXFURt7pERJuIGBURYyNifERcUNi/ekS8GhETI+LuiGhd2P+jwvuJheOr1XctBiaSJOVcIoq21eNrYOeU0iZAX2DXiOgPXAZclVJaC5gFHFMYfwwwq7D/qsK4OhmYSJKkBknV5hXetipsCdgZuLewfxiwV+H1gMJ7Csd/EhF1Rj8GJpIk5VwxSzkRMSgiRtfYBtWcKyLKImIM8BnwBPBvYHZKqaIwZArQs/C6JzAZoHB8DtClrmtxVY4kSTlXzGflpJQGA4PrOF4J9I2IzsADQJ8iTm/GRJIkfX8ppdnAM8BWQOeI+CbZ0QsoL7wuB3oDFI53AmbU9b0GJpIk5VxTNb9GRNdCpoSIaAvsAkygOkDZrzDsCOChwusRhfcUjj+dUqrzBvqWciRJyrmqpru/WndgWESUUZ3cGJ5SGhkR7wB3RcRFwJvAkML4IcBtETERmAkcWN8EBiaSJKlBUkrjgE2XsP8DYIsl7P8K2P/7zGFgIklSzvmsHEmSlBl1Nm3kjM2vkiQpM8yYSJKUc8W8j0lzMzCRJCnnquq+y3uuWMqRJEmZYcZEkqScK6XmVwMTSZJyrpR6TCzlSJKkzDBjIklSzjXhLekbnYGJJEk5V0p3frWUI0mSMsOMiSRJOeeqHEmSlBml1GNiKUeSJGWGGRNJknKulO5jYmAiSVLOlVKPiaUcSZKUGWZMJEnKuVJqfjUwkSQp50qpx8RSjiRJygwzJpIk5VwpZUwMTCRJyrlUQj0mlnIkSVJmmDGRJCnnLOVIkqTMKKXAxFKOJEnKDDMmkiTlXCndkt7ARJKknCulO79aypEkSZlhxkSSpJwrpeZXAxNJknKulAITSzmSJCkzzJhIkpRzrsqRJEmZUUqrcgxMJEnKOXtMJEmSGoEZE0mScs4eE0mSlBlVJRSaWMqRJEmZYcZEkqScK6XmVwMTSZJyrnQKOZZyJElShpgxkSQp5yzlSJKkzCilO79aypEkSZlhxkSSpJwrpfuYGJhIkpRzpROWWMqRJEkZYsZEkqScc1WOJEnKjFLqMbGUI0mSMsOMiSRJOVc6+RIDE0mScq+Uekws5UiSpMwwYyJJUs6VUvOrgYkkSTlXOmGJpRxJkpQhZkwkSco5m18lSVJmpCL+U5eI6B0Rz0TEOxExPiJOLuzvGxGvRMSYiBgdEVsU9kdEXBMREyNiXET8uL5rMWMiSZIaqgI4LaX0RkR0AF6PiCeAy4ELUkqPRMTuhfc7ArsBaxe2LYEbCv+ulYGJJEk511SlnJTSVGBq4fXnETEB6El1/23HwrBOwMeF1wOAW1NKCXglIjpHRPfC9yyRgYkkSTnXHMuFI2I1YFPgVeAU4LGIuILqNpGtC8N6ApNrfGxKYV+tgYk9JpIkaZGIGFToE/lmG7SEMe2B+4BTUkpzgeOBU1NKvYFTgSE/dH4zJpIk5Vwx8yUppcHA4NqOR0QrqoOSO1JK9xd2HwGcXHh9D3BT4XU50LvGx3sV9tXKjIkkSTlXRSraVpeICKqzIRNSSn+ucehjYIfC652B9wuvRwCHF1bn9Afm1NVfAmZMSsrXXy/giBPPYMHChVRWVLLLTtty0sDDvjPu0aee4/qhtxME6669Bpf//rdLNe+cuZ9z2rmX8vEnn9Jj5W5ceeHv6NSxAyMfe5ohd9wDCdq1a8u5p59En7XXWKq5pCzq2XNlrh/8J1ZaaUVSSgy7+W7+fsOw74zbZtstuOSyc2jVqiUzZszil7sdslTztm7dmhsGX84mfTdk1szZHH3kyUz+qJwdd9qG8y44ndatW7FgwULOP+cynn/ulaWaSyrYBjgMeCsixhT2nQUcC1wdES2Br4Bvyj8PA7sDE4H5wFH1TRDVjbKNZ+H0D0rpTrmZllLiyy+/ol27tiysqODw40/nzJOPY5MN11s0ZtLkck479xKGXPNHOnXswIxZs+myfOcGff+oN8bx0MNPcPE5py22/8rrhtCpYwcGHnYAN902nLmff86vTziGN996hzVW7U2njh14/uXXuH7oHdx541+Kes2qXbfVf97cp7DM6NatK91W7sq4se/Qvv1yPP38Axx24Am8997ERWM6durAY08OZ7+9j6Z8ylRWXHEFpk+f2aDv771KT67722Xsufuhi+0/euDBbLBhH0475Tz22XcP9vjlLhxz5ClstPH6TPtsOp988hnrrbc29zw4lA3X3a6o16y6zfz8/WjK+Y5dbf+i/a698cN7mvTcv81STgmJCNq1awtARUUFFRUVVGfd/r97RzzKgfv8kk4dOwAsFpQMveNefnXM/7D34cdz7U23NXjeZ55/mQG7/RSAAbv9lKefexmATTdaf9E8G2/Qh08/m/7DL07KsE8/nca4se8AMG/eF/zrvX/TvUe3xcbst/8v+d8Rj1M+pTqLXTMo2f9Xe/LEM/fy7Isj+PPVF9KiRcP+aN59j59y1z+qS/wPPfgo2++4FQBvjXuHTz75DIAJE96nbZs2tG7deukuUpnWVDdYawo/ODCJiHrTMWp6lZWV7HvEiWz/i4PYavNN2XiDPosdnzS5nEmTyzn0v07j4GNP4YVXRgPw4quv89GUcu666Wruu+U63nlvIqPHvNWgOWfMmk3XFVcAYMUuyzNj1uzvjLl/5GNs27/fUl6dlH29V+nJxhuvz+ujxy62f621Vqdz546MePh2nn7uAX510F4ArLPumuy97x7stsuB7LDNnlRWVrL/r/Zs0Fzde3SjfMonQPXP/tw581ihy/KLjdlzwK6MHTueBQsWFOHqpMa3ND0mFwA3F+tEVBxlZWXcN+w65n4+j5N/dyHvf/Aha6+x2qLjFZWVTJpSzs3XXsann03niBPP4IFbb+Cl197gpVFvsN+RJwEw/8svmTT5Y/r13YiDjj2FBQsWMv/LL5kz93P2PeJEAH59wtFss+Vmi80fEd/J0ox6fSz3j3yc2264onEvXmpmyy3XjmG3X8tZZ17M55/PW+xYWcsy+m66IXv94nDatG3DY08OZ/RrY9h+h63YpO8GPPVsdeajTdsfMX3aDABu/cd1rLpqb1q3bkXPXt159sURAPz9hmH84/b76j2fPn3W4vw/nMG+e/n3yFJXSs/KqTMwiYhxtR0CutVyjMKa50EA1195EQMPP+gHn6B+mI4d2rPFjzfmhVdGLxaYdOu6IhtvsC6tWrakV4+VWa13TyZNKYcEAw/7FQfstft3vuubvpDaeky6LN+ZadNn0nXFFZg2fSYrdO606Nh7E//DeX/8C3+78kI6d+qIVKpatmzJsNuv5d7hIxg54vHvHP/440+YNXM28+d/yfz5X/LyS6+x4YZ9iAju+scDXPj7K7/zmcMPrv5LQG09JlM//pSevVbm448/oaysjI6d2jNzxiwAevRYmVvvvJ4TjjuDD//zUSNcsbIkCyWYYqmvlNMNOBz45RK2GbV9KKU0OKXUL6XUz6Ck6cycNZu5hb+lffX117z82pusvmrvxcb8ZPuteO2N6nhz1uw5fDi5nN49urP1Fj/mgf97nPnzvwTg02nTl1iSWZIdt+3PQ488CcBDjzzJTttV17mnfvIZp5x1IZeedwarrdKrKNcoZdU1113Cv977N9dfu+RE8iP/9xRbbrUZZWVltG3bhs36bcK/3vs3z/3zZfYcsCsrFsqhnZfvRK/ePRo05yMPP8WBB+8DwIC9duX5Z6tX3nTs1IG77h3MH86/gldfeaMIVyc1nfpKOSOB9imlMd8+EBH/bJQz0g82bcYszr7oCiqrqkhViZ/vvB07brMl1954Kxv0WYedtuvPNltuxkuj3mDPQwZR1qKM0048hs6dOrLNlpvxwaTJHHLcrwFo17YNl553RoNW7Aw87ABOO/cS7h/5GD1WXokrLzwLgBtu/gdz5n7ORVdcB1SXmYYPvabx/gNIzWTLrTbjwIP3Zvzb7y4qt1x4wZX06lUdYNwy9E7+9d6/efrJ53nhlZFUVVVx27B7mDCh+lYPl1x4Ffc9dAstWgQLF1bwm9MuYMrkj2ud7xu333oPf7vxCkaPeZJZs2Yz8KhTATh20GGsvsaqnPHbkzjjt9Xl2X0HHNngVUDKn1Iq5bhcWCpRLheWmk9TLxc+bNV9iva79rZJ97tcWJIkCbzzqyRJuVdKpQkDE0mScq6+Z9zkiaUcSZKUGWZMJEnKuVK6j4mBiSRJOVdKy4Ut5UiSpMwwYyJJUs6VUvOrgYkkSTlXSj0mlnIkSVJmmDGRJCnnSqn51cBEkqSca+zn3jUlSzmSJCkzzJhIkpRzrsqRJEmZYY+JJEnKDJcLS5IkNQIzJpIk5Zw9JpIkKTNcLixJktQIzJhIkpRzrsqRJEmZ4aocSZKkRmDGRJKknHNVjiRJygxX5UiSJDUCMyaSJOWcpRxJkpQZrsqRJElqBGZMJEnKuaoSan41MJEkKedKJyyxlCNJkjLEjIkkSTnnqhxJkpQZpRSYWMqRJEmZYcZEkqScK6Vb0huYSJKUc5ZyJEmSGoEZE0mScq6UbklvYCJJUs6VUo+JpRxJkpQZZkwkScq5Ump+NTCRJCnnLOVIkiQ1AjMmkiTlnKUcSZKUGaW0XNhSjiRJygwzJpIk5VxVCTW/GphIkpRzlnIkSZIagRkTSZJyzlKOJEnKDEs5kiRJjcDARJKknKtKqWhbXSKid0Q8ExHvRMT4iDi5xrH/joh3C/svr7H/dxExMSLei4if13ctlnIkScq5JizlVACnpZTeiIgOwOsR8QTQDRgAbJJS+joiVgKIiPWBA4ENgB7AkxGxTkqpsrYJzJhIkqQGSSlNTSm9UXj9OTAB6AkcD/wxpfR14dhnhY8MAO5KKX2dUvoPMBHYoq45DEwkScomlRU5AAADHElEQVS5pirl1BQRqwGbAq8C6wDbRcSrEfFsRGxeGNYTmFzjY1MK+2plKUeSpJwrZiknIgYBg2rsGpxSGvytMe2B+4BTUkpzI6IlsALQH9gcGB4Ra/yQ+Q1MJEnSIoUgZHBtxyOiFdVByR0ppfsLu6cA96eUEjAqIqqAFYFyoHeNj/cq7KuVpRxJknIupaqibXWJiACGABNSSn+ucehBYKfCmHWA1sB0YARwYET8KCJWB9YGRtU1hxkTSZJyrqrpVuVsAxwGvBURYwr7zgKGAkMj4m1gAXBEIXsyPiKGA+9QvaLnxLpW5ICBiSRJaqCU0gtA1HL40Fo+czFwcUPnMDCRJCnnks/KkSRJWdGEpZxGZ/OrJEnKDDMmkiTlnKUcSZKUGd/njq1ZZylHkiRlhhkTSZJyrgmfLtzoDEwkSco5e0wkSVJmuFxYkiSpEZgxkSQp5yzlSJKkzHC5sCRJUiMwYyJJUs5ZypEkSZnhqhxJkqRGYMZEkqScs5QjSZIyw1U5kiRJjcCMiSRJOedD/CRJUmZYypEkSWoEZkwkSco5V+VIkqTMKKUeE0s5kiQpM8yYSJKUc5ZyJElSZpRSYGIpR5IkZYYZE0mScq508iUQpZT+UfFFxKCU0uDmPg9pWePPnpZVlnJUn0HNfQLSMsqfPS2TDEwkSVJmGJhIkqTMMDBRfaxxS83Dnz0tk2x+lSRJmWHGRJIkZYaBiZYoInaNiPciYmJEnNnc5yMtKyJiaER8FhFvN/e5SM3BwETfERFlwHXAbsD6wEERsX7znpW0zLgF2LW5T0JqLgYmWpItgIkppQ9SSguAu4ABzXxO0jIhpfQcMLO5z0NqLgYmWpKewOQa76cU9kmS1KgMTCRJUmYYmGhJyoHeNd73KuyTJKlRGZhoSV4D1o6I1SOiNXAgMKKZz0mStAwwMNF3pJQqgJOAx4AJwPCU0vjmPStp2RARdwIvA+tGxJSIOKa5z0lqSt75VZIkZYYZE0mSlBkGJpIkKTMMTCRJUmYYmEiSpMwwMJEkSZlhYCJJkjLDwESSJGWGgYkkScqM/wfKk5vAbFTtmgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "run_KNN(symbol_name = 'MSFT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting File from:  ../data/alphaVantage/AAPL-full-daily_adjusted.csv\n",
      "1309\n",
      "0.5217723453017571\n",
      "1.0 \t 1.0\n",
      "1.0 \t 1.0\n",
      "1.0 \t 1.0\n",
      "1.0 \t 1.0\n",
      "1.0 \t 1.0\n",
      "-1.0 \t 1.0\n",
      "Getting File from:  ../data/alphaVantage/AAPL-full-daily_adjusted.csv\n",
      "1309\n",
      "0.5064935064935064\n",
      "1.0 \t 1.0\n",
      "1.0 \t 1.0\n",
      "-1.0 \t 1.0\n",
      "1.0 \t 1.0\n",
      "1.0 \t 1.0\n",
      "-1.0 \t 1.0\n",
      "Getting File from:  ../data/alphaVantage/AAPL-full-daily_adjusted.csv\n",
      "1309\n",
      "0.5049656226126814\n",
      "1.0 \t 1.0\n",
      "1.0 \t 1.0\n",
      "1.0 \t 1.0\n",
      "1.0 \t 1.0\n",
      "1.0 \t 1.0\n",
      "-1.0 \t 1.0\n",
      "0.5095492742551566\n",
      "1.0 \t 1.0\n",
      "1.0 \t 1.0\n",
      "1.0 \t 1.0\n",
      "1.0 \t 1.0\n",
      "1.0 \t 1.0\n",
      "-1.0 \t 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "symbol_name = 'AAPL'\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = hm.prepare_data(1, symbol_name)\n",
    "X_train, X_test, Y_train, Y_test = X_train.values, X_test.values, Y_train.values, Y_test.values\n",
    "print(len(Y_test))\n",
    "clf1 = KNeighborsClassifier(n_neighbors=13)\n",
    "clf1.fit(X_train, Y_train)\n",
    "y_pred = clf1.predict(X_test)\n",
    "print(accuracy_score(y_pred, Y_test))\n",
    "cum_y_pred = y_pred\n",
    "\n",
    "for i in range(5, -1, -1):\n",
    "    print(y_pred[-i], '\\t', Y_test[-1])\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = hm.prepare_data(1, symbol_name)\n",
    "X_train, X_test, Y_train, Y_test = X_train.values, X_test.values, Y_train.values, Y_test.values\n",
    "print(len(Y_test))\n",
    "clf2 = KNeighborsClassifier(n_neighbors=11)\n",
    "clf2.fit(X_train, Y_train)\n",
    "y_pred = clf2.predict(X_test)\n",
    "print(accuracy_score(y_pred, Y_test))\n",
    "cum_y_pred += y_pred\n",
    "\n",
    "for i in range(5, -1, -1):\n",
    "    print(y_pred[-i], '\\t', Y_test[-1])\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = hm.prepare_data(1, symbol_name)\n",
    "X_train, X_test, Y_train, Y_test = X_train.values, X_test.values, Y_train.values, Y_test.values\n",
    "print(len(Y_test))\n",
    "clf3 = KNeighborsClassifier(n_neighbors=9)\n",
    "clf3.fit(X_train, Y_train)\n",
    "y_pred = clf3.predict(X_test)\n",
    "print(accuracy_score(y_pred, Y_test))\n",
    "cum_y_pred += y_pred\n",
    "\n",
    "for i in range(5, -1, -1):\n",
    "    print(y_pred[-i], '\\t', Y_test[-1])\n",
    "\n",
    "\n",
    "cum_y_pred = np.abs(cum_y_pred) / cum_y_pred\n",
    "print(accuracy_score(cum_y_pred, Y_test))\n",
    "\n",
    "for i in range(5, -1, -1):\n",
    "    print(cum_y_pred[-i], '\\t', Y_test[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
