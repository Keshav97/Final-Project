{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Jupyter notebook from preprocessing.ipynb\n"
     ]
    }
   ],
   "source": [
    "import nbimporter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import preprocessing as pp\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This fumction calculates and returns the Mean Squared Error (MSE) for a model\n",
    "def mean_squared_error(Y_true, Y_pred):\n",
    "    # number of test samples\n",
    "    M = len(Y_true)\n",
    "    total_error = 0\n",
    "    for i in range(M):\n",
    "        total_error += (Y_true[i] - Y_pred[i]) ** 2\n",
    "    mse = total_error / M\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function splits the data into train and test sets based on the split ratio supplied and \n",
    "# returns the corresponding X and Y values for the train and test data\n",
    "def train_test_split(df, train_ratio = 0.75):\n",
    "    split_index = int(train_ratio * len(df.index))\n",
    "    \n",
    "    train_data = df.iloc[0:split_index, :]\n",
    "    test_data = df.iloc[split_index:, :]\n",
    "    \n",
    "    X_train, Y_train = train_data.iloc[:, :-1], train_data.iloc[:, -1]\n",
    "    X_test, Y_test = test_data.iloc[:, :-1], test_data.iloc[:, -1]\n",
    "    \n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function splits the input data into corresponding X(features) and Y(output) values\n",
    "# The Y(output) values are assumed to be in the last column of the input data\n",
    "def get_X_Y(data):\n",
    "    X_data = list()\n",
    "    Y_data = list()\n",
    "    for i in data:\n",
    "        X_data.append(i[:-1])\n",
    "        Y_data.append(i[-1])\n",
    "    return X_data, Y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT: This function taken in the Symbol of the stock data to be studied and eventually predicted \n",
    "#\n",
    "# It prepares the data for training by fetching the data for the mentioned stock, calculating the daily returns of the stock, \n",
    "# and adding corresponding features for each datapoint using n previous returns. \n",
    "# It further splits the built dataframe into training and test sets\n",
    "# \n",
    "# RETURN: It returns X and Y values for the train and test sets ready to start work upon\n",
    "\n",
    "def prepare_data(num_features, symbol_name = 'AAPL'):\n",
    "    df = pp.read_file(symbol_name)\n",
    "    df = pp.data_daily_returns(df)\n",
    "    \n",
    "    # number of datapoints in the data frame\n",
    "    M = len(df.index)\n",
    "    \n",
    "    # creating columns for t = (t0 - n) return to t = t0 return\n",
    "    col_names = [str(i) for i in range(num_features, -1, -1)]\n",
    "    \n",
    "    # creating dataframe to store the RETURNS data points with correpsonding features\n",
    "    data = pd.DataFrame()\n",
    "    \n",
    "    for i in range(num_features + 1):\n",
    "        # gets the indices of the datapoints to build the features corresponding to RETURNS at t = t0 - (num_features - i)\n",
    "        indices_to_fetch = df.index[i:(M - num_features + i)]\n",
    "        \n",
    "        temp = df.loc[indices_to_fetch, 'RETURNS']\n",
    "        temp.index = df.index[num_features:]\n",
    "        \n",
    "        data[str(num_features - i)] = temp\n",
    "\n",
    "    return train_test_split(data, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_features = 5\n",
    "X_train, X_test, Y_train, Y_test = prepare_data(num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation\n",
    "http://francescopochetti.com/pythonic-cross-validation-time-series-pandas-scikit-learn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeSeriesCV(X_train, Y_train, num_folds, algorithm, parameters):\n",
    "    print('Parameters ------------------------>', parameters)\n",
    "#     print('Number of folds:', num_folds)\n",
    "#     print('Size train set:', X_train.shape)\n",
    "    \n",
    "    k = int(np.floor(float(X_train.shape[0]) / num_folds))\n",
    "#     print('Size of each fold:', k)\n",
    "    \n",
    "    accuracies = np.zeros(num_folds - 1)\n",
    "    \n",
    "    for i in range(2, num_folds + 1):\n",
    "#         print('')\n",
    "        \n",
    "        split = float(i - 1)/i\n",
    "#         print('Splitting the first ' + str(i) + ' chunks at ' + str(i - 1) + '/' + str(i))\n",
    "        \n",
    "        X = X_train[:(k * i)]\n",
    "        Y = Y_train[:(k * i)]\n",
    "#         print('Size of train + test:', X.shape)\n",
    "        \n",
    "        index = int(np.floor(X.shape[0] * split))\n",
    "        \n",
    "        X_trainFolds = X[:index]\n",
    "        Y_trainFolds = Y[:index]\n",
    "        \n",
    "        X_testFolds = X[index:]\n",
    "        Y_testFolds = Y[index:]\n",
    "        \n",
    "        Y_pred = algorithm(X_trainFolds, Y_trainFolds, X_testFolds, parameters[0])\n",
    "        \n",
    "        accuracies[i - 2] = r2_score(Y_testFolds, Y_pred)\n",
    "#         print('Accuracy of fold ' + str(i) + ':' + str(accuracies[i - 2]))\n",
    "    \n",
    "    return accuracies.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
