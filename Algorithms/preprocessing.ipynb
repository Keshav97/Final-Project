{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import mlab\n",
    "import scipy as sp\n",
    "import seaborn as sns # statistical visualisation\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import math\n",
    "from sklearn import preprocessing as pp\n",
    "\n",
    "sns.set() # to have nore appealing visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function: Prints out the data description and returns the head of the data\n",
    "def data_describe(data):\n",
    "    print(data.describe())\n",
    "    return data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes file name at a given location\n",
    "# Returns dataframe corresponding to data in file\n",
    "def read_file(company_symbol = 'AAPL'):\n",
    "    column_names = [\n",
    "                    'INDEX', 'DATE', 'OPEN', \n",
    "                    'HIGH', 'LOW', 'CLOSE',\n",
    "                    'ADJ_CLOSE', 'VOLUME', \n",
    "                    'DIV_AMT', 'SPLIT_COEFF'\n",
    "                   ]\n",
    "#     filepath = '../data/alphaVantage/AAPL-full-daily_adjusted.csv'\n",
    "    filepath = '../data/alphaVantage/' + company_symbol + '-full-daily_adjusted.csv'\n",
    "    df = pd.read_csv(filepath, skiprows=1, header=None, names=column_names, index_col=['DATE'], parse_dates=['DATE'])\n",
    "    df.drop(columns=['INDEX'], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_symbol = 'MSFT'\n",
    "stocks = read_file(company_symbol)\n",
    "print(stocks.info())\n",
    "data_describe(stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function plots the parameter specified for a given dataframe\n",
    "def visualise_plot(df, param, title):\n",
    "    df[param].plot(figsize=(20,10), fontsize=20)\n",
    "    plt.xlabel('Year', fontsize=20)\n",
    "    plt.title(title, fontsize=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_plot(stocks, 'ADJ_CLOSE', 'Stock (adjusted) close values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting to Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function returns the daily returns of the stock based on a specified parameter within the data (Using Taylor series approximation)\n",
    "def data_log_returns(data, param = 'ADJ_CLOSE'):\n",
    "    log_returns = list()\n",
    "    date = list()\n",
    "    for i in range(len(data) - 1):\n",
    "        abs_t1 = math.log10(data.loc[data.index[i], param])\n",
    "        abs_t0 = math.log10(data.loc[data.index[i + 1], param])\n",
    "        log_returns.append(abs_t1 - abs_t0)\n",
    "        date.append(data.index[i])\n",
    "    return pd.DataFrame(log_returns, index=date, columns=['RETURNS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_returns = data_log_returns(stocks, 'ADJ_CLOSE')\n",
    "visualise_plot(stock_returns, 'RETURNS', 'Stock Daily Returns')\n",
    "data_describe(stock_returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling\n",
    "### 1. Standard Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function performs Standard Scaling on the data to get 0 mean and 1 Standard Deviation\n",
    "def standard_scaling_data(data):\n",
    "    temp = data\n",
    "    standardScaler = pp.StandardScaler()\n",
    "    column_names = temp.columns\n",
    "    standardScaler.fit(temp)\n",
    "    data = pd.DataFrame(standardScaler.transform(temp), \n",
    "                        index=data.index, \n",
    "                        columns = column_names)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scaled_stock_returns = standard_scaling_data(stock_returns)\n",
    "visualise_plot(std_scaled_stock_returns, 'RETURNS', 'Stock (Standard) Scaled Daily Returns')\n",
    "data_describe(std_scaled_stock_returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Min-Max Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function performs Min-Max Scaling on the data to scale the data between a certain minimum and maximum\n",
    "def min_max_scaling_data(data, min, max):\n",
    "    temp = data\n",
    "    minMaxScaler = pp.MinMaxScaler(feature_range=(min,max))\n",
    "    column_names = temp.columns\n",
    "    temp = minMaxScaler.fit_transform(temp)\n",
    "    data = pd.DataFrame(temp, index=data.index, columns = column_names)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax_scaled_stock_returns = min_max_scaling_data(stock_returns, 0, 1)\n",
    "visualise_plot(minmax_scaled_stock_returns, 'RETURNS', 'Stock (Min-Max) Scaled Daily Returns')\n",
    "data_describe(minmax_scaled_stock_returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decomposition\n",
    "### 1. Rolling Average Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function plots the rolling average trend for a given dataframe and parameter\n",
    "# Default window size of 252 days rolling around a year (Number of trading days in a year = 252)\n",
    "def plot_rolling_average_trend(df, decomposition_param, window = 252):\n",
    "    df[decomposition_param].rolling(window).mean().plot(figsize=(20,10), linewidth=2, fontsize=20) \n",
    "    # plotting the trend\n",
    "    plt.title(\"Rolling Average Trend\", fontsize=20)\n",
    "    plt.xlabel('Year', fontsize=20);\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function plots the dataframe after trend removal using rolling mean\n",
    "def plot_detrended_rolling_average(df, decomposition_param):\n",
    "    daily_returns = df[decomposition_param]\n",
    "    # Removing the trend (to see the seasonality and noise)\n",
    "    daily_returns_detrend = daily_returns.diff()\n",
    "    daily_returns_detrend.plot(figsize=(20,10), fontsize=20)\n",
    "    plt.title('Data: Seasonality + Residue (Trend Rolling Mean)', fontsize=20)\n",
    "    plt.xlabel('Year', fontsize=20);\n",
    "    plt.show()\n",
    "\n",
    "    # Scatter Plot\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.scatter(daily_returns.index, daily_returns_detrend)\n",
    "    plt.title('Data: Seasonality + Residue (Trend Rolling Mean)', fontsize=20)\n",
    "    plt.xlabel('Year', fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = stocks\n",
    "# decomposition_param = 'ADJ_CLOSE'\n",
    "\n",
    "df = stock_returns\n",
    "# df = std_scaled_stock_returns\n",
    "# df = minmax_scaled_stock_returns\n",
    "decomposition_param = 'RETURNS'\n",
    "\n",
    "plot_rolling_average_trend(df, decomposition_param, 252)\n",
    "plot_detrended_rolling_average(df, decomposition_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Using statsmodel sesasonal_deocmpose\n",
    "Basics - https://machinelearningmastery.com/decompose-time-series-data-trend-seasonality/\n",
    "\n",
    "Frequency adjustment - https://stackoverflow.com/a/47610117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function uses statsmodel sesasonal_deocmpose to plot the trend, seasonality and residue of the input dataframe\n",
    "# Model: 'additive' or 'multiplicative'\n",
    "def series_decomposition(df, param, model):\n",
    "    result = seasonal_decompose(df[param], model=model, freq=252)\n",
    "    result.plot()\n",
    "    plt.xlabel('Year')\n",
    "    plt.show()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = stocks\n",
    "# decomposition_param = 'ADJ_CLOSE'\n",
    "\n",
    "df = stock_returns\n",
    "# df = std_scaled_stock_returns\n",
    "# df = minmax_scaled_stock_returns\n",
    "decomposition_param = 'RETURNS'\n",
    "\n",
    "# df = min_max_scaling_data(stock_returns, 1, 2)\n",
    "\n",
    "\n",
    "\n",
    "# Additive Decomposition using statsmodel seasonal decompose\n",
    "print('Additive Decomposition:')    \n",
    "add_decom = series_decomposition(df, decomposition_param, 'additive')\n",
    "print('Additive: Seasonlity and Residue')\n",
    "(add_decom.seasonal + add_decom.resid).plot(figsize=(20,10))\n",
    "plt.show()\n",
    "\n",
    "# Multiplicative Decomposition using statsmodel seasonal decompose\n",
    "# print('Multiplicative Decomposition:')    \n",
    "# mult_decom = series_decomposition(df, decomposition_param, 'multiplicative')\n",
    "# print('Multiplicative: Seasonlity and Residue')\n",
    "# (mult_decom.seasonal*mult_decom.resid).plot()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Autocorrelation\n",
    "**Autocorrelation** is the correlation of a signal with a delayed copy of itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes in a dataframe and the index of a column to plot the autocorrelation\n",
    "def plot_autocorrelation(df, decomposition_param_index):\n",
    "    # Printing autocorrelation for a particular lag value\n",
    "    lag = 1\n",
    "    print('Lag:', lag, '\\t autocorrelation:', df.iloc[:, decomposition_param_index].diff().autocorr(lag=lag))\n",
    "    \n",
    "    plt.figure(figsize=(20,10))\n",
    "    pd.plotting.autocorrelation_plot(df.iloc[:, decomposition_param_index])\n",
    "    plt.title('Autocorrelation Plot', fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = stocks\n",
    "# decomposition_param = 'ADJ_CLOSE'\n",
    "# decomposition_param_index = 4\n",
    "\n",
    "# df = stock_returns\n",
    "# print(stock_returns.head())\n",
    "df = std_scaled_stock_returns\n",
    "# df = minmax_scaled_stock_returns\n",
    "# decomposition_param = 'RETURNS'\n",
    "decomposition_param_index = 0\n",
    "\n",
    "plot_autocorrelation(df, decomposition_param_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO plot the absolute values of returns on the log-log scale\n",
    "# This function compares the data distribution to normal distribution\n",
    "def plot_distribution(data, distribution='cdf'):\n",
    "    # Plot the histogram.\n",
    "    data.hist(bins=100, density=True, alpha=0.6, cumulative = True)\n",
    "\n",
    "    # Get parameters of normal distribution i.e the mean and the variance:\n",
    "    mu = 0\n",
    "    variance = 1\n",
    "    sigma = math.sqrt(variance)\n",
    "\n",
    "    if distribution == 'cdf':\n",
    "        # Plot the CDF.\n",
    "        x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n",
    "        plt.plot(x, sp.stats.norm.cdf(x, mu, sigma))\n",
    "    elif distribution == 'pdf':\n",
    "        # Plot the PDF.\n",
    "        x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n",
    "        plt.plot(x, sp.stats.norm.pdf(x, mu, sigma))\n",
    "        \n",
    "    # plt.yscale(\"log\")\n",
    "    # plt.xscale(\"log\")\n",
    "    plt.title(\"Returns vs Normal Distribution\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some data for plotting the data distribution\n",
    "data = std_scaled_stock_returns\n",
    "plot_distribution(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Kurtosis and Skew\n",
    "https://www.itl.nist.gov/div898/handbook/eda/section3/eda35b.htm  \n",
    "\n",
    "**Skewness** is usually described as a measure of a dataset’s symmetry – or lack of symmetry.   A perfectly symmetrical data set will have a skewness of 0. The normal distribution has a skewness of 0.  \n",
    "https://www.spcforexcel.com/knowledge/basic-statistics/are-skewness-and-kurtosis-useful-statistics#skewness  \n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.skew.html  \n",
    "  \n",
    "**Kurtosis** is all about the tails of the distribution – not the peakedness or flatness.  It measures the tail-heaviness of the distribution. The normal distribution has a kurtosis of 0.  \n",
    "(Kurtosis is the degree of peakedness of a distribution – Wolfram MathWorld)  \n",
    "https://www.spcforexcel.com/knowledge/basic-statistics/are-skewness-and-kurtosis-useful-statistics#kurtosis  \n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kurtosis.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function prints the skewness and kurtosis for the given data frame \n",
    "def skewness_kurtosis(df):\n",
    "    print(\"Skewness: \", sp.stats.skew(df))\n",
    "    print(\"Kurtosis: \", sp.stats.kurtosis(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "skewness_kurtosis(std_scaled_stock_returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Volatility\n",
    "https://www.packtpub.com/mapt/book/big_data_and_business_intelligence/9781787123137/15/ch15lvl1sec133/calculating-the-volatility-of-stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes in the dataframe, a parameter and the window frame\n",
    "# The function calculates the volatility of the parameter specified within a\n",
    "# given time window and plots the volatility of the parameter over the course of the data\n",
    "def plot_volatility_curve(df, param, window = 252):\n",
    "    vol = df[decomposition_param].rolling(window=window).std() * np.sqrt(window)\n",
    "    vol.plot(figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = stocks\n",
    "# decomposition_param = 'ADJ_CLOSE'\n",
    "\n",
    "# df = stock_returns\n",
    "df = std_scaled_stock_returns\n",
    "# df = minmax_scaled_stock_returns\n",
    "decomposition_param = 'RETURNS'\n",
    "\n",
    "plot_volatility_curve(df, decomposition_param, window = 252)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. P-Dickey Fuler Test\n",
    "https://www.statsmodels.org/dev/generated/statsmodels.tsa.stattools.adfuller.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function implements the Rolling Mean and Augmented Dickey-Fuller test for stationarity\n",
    "def test_stationarity(df, decomposition_param='RETURNS', window = 252):\n",
    "    # Determing rolling statistics \n",
    "    rolmean = df[decomposition_param].rolling(window).mean()\n",
    "    rolstd = df[decomposition_param].rolling(window).std()\n",
    "    \n",
    "    plt.figure(figsize=(20,10))\n",
    "    \n",
    "    # Plot rolling statistics:\n",
    "    orig = plt.plot(df[decomposition_param], color='blue',label='Original')\n",
    "    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n",
    "    std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.title('Rolling Mean & Standard Deviation')\n",
    "    plt.show()\n",
    "    \n",
    "    #Perform Dickey-Fuller test:\n",
    "    print('Results of Dickey-Fuller Test:')\n",
    "    dftest = adfuller(df[decomposition_param], autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)'%key] = value\n",
    "    print(dfoutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stationarity(std_scaled_stock_returns, 'RETURNS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. plot the absolute values of returns on the log-log scale  \n",
    "2. pdf and cdf\n",
    "3. p-Dickey Fuller Test \n",
    "4. Implement algorithms"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
